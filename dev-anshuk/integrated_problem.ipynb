{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emily's state transition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"Plots\")\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"Distributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, Random, DataFrames\n",
    "using GLMakie\n",
    "using GeoDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TR_orbit_clean (generic function with 2 methods)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../dev-yuji/heuristics.jl\")\n",
    "include(\"state.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../src/obs_site_Earth_50.csv\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"../src/obs_site_Earth_50.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constants\n",
    "Re = 6371;\n",
    "mu_E = 3.986004418e5; #km^3/m^2  \n",
    "slew_limit = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTS Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A shortened representation of MDP that works for online planning (no full state-space, TR captures T and R)\n",
    "struct MDP \n",
    "    gamma # Discount factor\n",
    "    A # Action space\n",
    "    TR # Transition model\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feasible_actions (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rollout(P, s, d)\n",
    "    s_ = copy(s)\n",
    "    ret = 0.0 \n",
    "    for t in 1:d\n",
    "        a = rand(P.A)\n",
    "        # a = heuristic_action(s, slew_limit)\n",
    "        s_, r = P.TR(s_, a)\n",
    "        ret += P.gamma^(t-1) * r\n",
    "    end \n",
    "    return ret \n",
    "end\n",
    "\n",
    "struct MonteCarloTreeSearch\n",
    "    P\n",
    "    N   # visit count\n",
    "    Q   # action-value estimate\n",
    "    d   # depth to go through for the Monte Carlo search\n",
    "    d_r # depth to go through the rollout at the end of the MCTS\n",
    "    m   # num of simulations\n",
    "    c   # exploration constant \n",
    "    U   # value function estimate \n",
    "end \n",
    "\n",
    "function (π::MonteCarloTreeSearch)(s)\n",
    "    for k in 1:π.m\n",
    "        simulate!(π,s)\n",
    "    end \n",
    "    return argmax(a->π.Q[(s,a)], π.P.A)\n",
    "end \n",
    "\n",
    "function simulate!(π::MonteCarloTreeSearch, s, d=π.d)\n",
    "    if d <= 0 \n",
    "        return rollout(π.P, s, π.d_r)\n",
    "    end \n",
    "    P, N, Q, c = π.P, π.N, π.Q, π.c\n",
    "    A, TR, gamma = P.A, P.TR, P.gamma\n",
    "    if !haskey(N,(s,first(A)))  # if (s,a) has never been visited\n",
    "        for a in A\n",
    "            N[(s,a)] = 0 \n",
    "            Q[(s,a)] = 0\n",
    "        end \n",
    "        return rollout(π.P, s, π.d_r)   \n",
    "    end\n",
    "    \n",
    "    # if (s,a) has been visited\n",
    "    a = explore(π,s)\n",
    "    # println(\"State before TR in simulate \\n\", s)\n",
    "    s_, r = TR(s,a)\n",
    "    # println(\"State after TR in simulate \\n\", s)\n",
    "    q = r + gamma* simulate!(π, s_, d-1) \n",
    "    N[(s,a)] += 1  # +1 for visit count \n",
    "    Q[(s,a)] += (q-Q[(s,a)]) / N[(s,a)]  # The more you visited, the update of the Q will (usually) converge \n",
    "    return q \n",
    "end \n",
    "\n",
    "bonus(Nsa, Ns) = Nsa==0 ? Inf : sqrt(log(Ns)/Nsa)\n",
    "\n",
    "function explore(π::MonteCarloTreeSearch, s)\n",
    "    A, N, Q, c = π.P.A, π.N, π.Q, π.c\n",
    "    Ns = sum(N[(s,a)] for a in A)\n",
    "    # objective = Q+bonus term \n",
    "    # if there is no past visit, then that exploration is always prioritized \n",
    "    return argmax(a -> Q[(s,a)] + c*bonus(N[(s,a)], Ns), A)  \n",
    "end \n",
    "\n",
    "function feasible_actions(s, A)\n",
    "    # s: Current state\n",
    "    # A: Total action space\n",
    "    new_action_space = [1] # initialize with do nothing\n",
    "    for action in A\n",
    "        if action > 1\n",
    "            rv = koe2cart(copy(s.koe), mu_E)\n",
    "            target = s.target_list[action-1]\n",
    "            target_pos = ECEF_to_ECI([target[1], target[2], target[3], 0, 0, 0], s.dt)\n",
    "            R_eci2rtn = ECI_to_RTN_matrix(rv)\n",
    "            look_vec_rtn = R_eci2rtn * (target_pos[1:3] .- rv[1:3]) \n",
    "            \n",
    "            horizon_dist = sqrt(norm(rv[1:3])^2 - Re^2)\n",
    "            far_side = norm(look_vec_rtn) > horizon_dist\n",
    "            if far_side\n",
    "            else\n",
    "                push!(new_action_space, action)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return new_action_space\n",
    "end\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the problem with Heuristic actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 99.0%1\n",
      "Progress: [====================] 99.0%2\n",
      "Progress: [====================] 99.0%3\n",
      "Progress: [====================] 99.0%4\n",
      "Progress: [====================] 99.0%5\n",
      "Progress: [====================] 99.0%6\n",
      "Progress: [====================] 99.0%7\n",
      "Progress: [====================] 99.0%8\n",
      "Progress: [====================] 99.0%9\n",
      "Progress: [====================] 99.0%10\n",
      "Final reward: 9.271619889644962\n"
     ]
    }
   ],
   "source": [
    "# setup parameters\n",
    "num_runs = 10\n",
    "reward_totals = zeros(num_runs)\n",
    "num_observed = zeros(num_runs)\n",
    "target_list, n_targets = create_target_list_3d(dataset)\n",
    "\n",
    "state_list = []\n",
    "action_list = []\n",
    "\n",
    "# Initializing state\n",
    "koe0 = [\n",
    "    7057.0,  # a [km]\n",
    "    0.000879,  # e\n",
    "    deg2rad(98.12),  # i\n",
    "    deg2rad(255.09),  # Ω [rad]\n",
    "    deg2rad(225.37),  # ω [rad]\n",
    "    deg2rad(75.0),  # M [rad]\n",
    "]\n",
    "att = [0.,0.]\n",
    "dt = 0\n",
    "\n",
    "observed_list = zeros(n_targets)\n",
    "state = State3d(koe0, att, dt, target_list, observed_list)\n",
    "\n",
    "for j in 1:num_runs\n",
    "    A = 1:n_targets+1 \n",
    "\n",
    "    time_step = 30 # seconds\n",
    "    num_minutes = 30\n",
    "    slew_limit = 15\n",
    "\n",
    "    # Create an intial state\n",
    "    # x0 = 0 # checl: are the test points centered around x=0?\n",
    "    # y0 = 0\n",
    "    # dydt = 1\n",
    "    # alt = 50\n",
    "    # for i in 1:num_runs\n",
    "    koe0 = [\n",
    "        7057.0,  # a [km]\n",
    "        0.000879,  # e\n",
    "        deg2rad(98.12),  # i\n",
    "        deg2rad(255.09),  # Ω [rad]\n",
    "        deg2rad(225.37),  # ω [rad]\n",
    "        deg2rad(75.0),  # M [rad]\n",
    "    ]\n",
    "    att = [0.,0.]\n",
    "    dt = 0\n",
    "    \n",
    "    observed_list = zeros(n_targets)\n",
    "    state = State3d(koe0, att, dt, target_list, observed_list)\n",
    "    state_list = []\n",
    "    action_list = []\n",
    "    for t in 0:time_step:2000\n",
    "        state_copy = copy(state)\n",
    "        push!(state_list, state_copy)\n",
    "        action = heuristic_action(state, slew_limit)\n",
    "        push!(action_list, action)\n",
    "        state, reward = TR_orbit(state, action, time_step)\n",
    "        reward_totals[j] += reward\n",
    "\n",
    "        # Calculate progress percentage\n",
    "        progress = t / 2000 * 100\n",
    "\n",
    "        # Create a string representation of the progress bar\n",
    "        bar_length = 20\n",
    "        bar_progress = round(Int, progress / (100 / bar_length))\n",
    "        bar_string = \"[\" * repeat(\"=\" , bar_progress) * repeat(\" \" , bar_length - bar_progress) * \"]\"\n",
    "\n",
    "        # Print the progress bar\n",
    "        print(\"\\rProgress: $bar_string $(round(progress, digits=2))%\")\n",
    "\n",
    "        # Sleep for a short duration to see the progress bar\n",
    "        sleep(0.1)\n",
    "    end\n",
    "    num_observed[j] = sum(state.observed_list)\n",
    "    println(j)\n",
    "end\n",
    "\n",
    "println(\"Final reward: \", mean(reward_totals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward 9.271619889644962\n",
      "Median number of sites observed 17.0\n"
     ]
    }
   ],
   "source": [
    "println(\"Average reward \", mean(reward_totals))\n",
    "println(\"Median number of sites observed \", median(num_observed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       "  8.557747023353961\n",
       "  9.34357951055156\n",
       "  8.634630432065844\n",
       " 12.468316999132448\n",
       " 10.12173525988986\n",
       "  9.424690148459822\n",
       "  9.436974931085498\n",
       "  8.125560009185737\n",
       "  8.498794072642392\n",
       "  8.104170510082481"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(dataset, DataFrame)\n",
    "target_lambda = df.lambda\n",
    "target_phi = df.phi\n",
    "target_mean_reward = df.r_mean\n",
    "observed_target_lambda = []\n",
    "observed_target_phi = []\n",
    "observed_target_reward = []\n",
    "for i in 1:length(state.observed_list)\n",
    "    if state.observed_list[i] == 1\n",
    "        push!(observed_target_lambda, target_lambda[i])\n",
    "        push!(observed_target_phi, target_phi[i])\n",
    "        push!(observed_target_reward, target_mean_reward[i])\n",
    "    end\n",
    "end\n",
    "observed_target_lambda = Float64.(observed_target_lambda)\n",
    "observed_target_phi = Float64.(observed_target_phi)\n",
    "observed_target_reward = Float64.(observed_target_reward)\n",
    "\n",
    "angs_list = []\n",
    "for i in 1:length(action_list)\n",
    "    # println(i)\n",
    "    action = action_list[i]\n",
    "    # println(action)\n",
    "    state = state_list[i]\n",
    "    # println(state)\n",
    "    if action > 1\n",
    "        target = state.target_list[action-1]\n",
    "        push!(angs_list, get_slew_angle(state.koe, target, state.dt))\n",
    "    else \n",
    "        if i > 1\n",
    "            push!(angs_list, angs_list[i-1])\n",
    "        else\n",
    "            push!(angs_list, (0,0))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "angs_list = collect(angs_list)\n",
    "cross_ang_des = [t[1] for t in angs_list];\n",
    "along_ang_des = [t[2] for t in angs_list];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the given problem with MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [=============       ] 64.5%"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "target_list, n_targets = create_target_list_3d(dataset)\n",
    "num_runs = 1\n",
    "mcts_reward_totals = zeros(num_runs)\n",
    "mcts_num_observed = zeros(num_runs)\n",
    "target_list, n_targets = create_target_list_3d(dataset)\n",
    "action_space =  1:n_targets+1 \n",
    "\n",
    "# MCTS parameters\n",
    "gamma = 0.95 # discount factor for the MDP problem\n",
    "m = 500 # simulation count\n",
    "c = 4000 # exploration constant\n",
    "d = 30 # simulation depth\n",
    "d_r = 1 # rollout depth\n",
    "P = MDP(gamma, action_space, TR_orbit)\n",
    "time_step = 30\n",
    "\n",
    "state_list_mcts = []\n",
    "action_list_mcts = []\n",
    "# Create an intial state\n",
    "for j in 1:num_runs\n",
    "    koe0 = [\n",
    "        7057.0,  # a [km]\n",
    "        0.000879,  # e\n",
    "        deg2rad(98.12),  # i\n",
    "        deg2rad(255.09),  # Ω [rad]\n",
    "        deg2rad(225.37),  # ω [rad]\n",
    "        deg2rad(75.0),  # M [rad]\n",
    "    ]\n",
    "    att = [0.,0.]\n",
    "    dt = 0\n",
    "    observed_list = zeros(n_targets)\n",
    "    state = State3d(koe0, att, dt, target_list, observed_list)\n",
    "\n",
    "    Q = Dict{Tuple{State3d, Int}, Float64}()\n",
    "    N = Dict{Tuple{State3d, Int}, Int}()\n",
    "    U = Dict{State, Float64}()\n",
    "\n",
    "    # Q, N, and U are going to be difficult to define\n",
    "    mcts_run = MonteCarloTreeSearch(P, N, Q, d, d_r, m, c, U)\n",
    "\n",
    "    state_list_mcts = []\n",
    "    action_list_mcts = []\n",
    "    for t = 0:time_step:2000\n",
    "        # Push to the full list\n",
    "        state_copy = copy(state)\n",
    "        push!(state_list_mcts, state_copy)\n",
    "        # println(\"State copy\")\n",
    "        # println(state_copy.observed_list)\n",
    "\n",
    "        # Run MCTS\n",
    "        state_for_mcts = copy(state)\n",
    "        mcts_action = mcts_run(state_for_mcts)\n",
    "\n",
    "        # Use the action\n",
    "        push!(action_list_mcts, mcts_action)\n",
    "        state, reward = TR_orbit(state, mcts_action, time_step)\n",
    "        mcts_reward_totals[j] += reward\n",
    "\n",
    "        # Calculate progress percentage\n",
    "        progress = t / 2000 * 100\n",
    "\n",
    "        # Create a string representation of the progress bar\n",
    "        bar_length = 20\n",
    "        bar_progress = round(Int, progress / (100 / bar_length))\n",
    "        bar_string = \"[\" * repeat(\"=\" , bar_progress) * repeat(\" \" , bar_length - bar_progress) * \"]\"\n",
    "\n",
    "        # Print the progress bar\n",
    "        print(\"\\rProgress: $bar_string $(round(progress, digits=2))%\")\n",
    "\n",
    "        # Sleep for a short duration to see the progress bar\n",
    "        sleep(0.1)\n",
    "    end\n",
    "    mcts_num_observed[j] = sum(state.observed_list)\n",
    "    println(j)\n",
    "end\n",
    "println(\"Final reward: \", mean(mcts_reward_totals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Average reward \", mean(mcts_reward_totals))\n",
    "println(\"Median number of sites observed \", median(mcts_num_observed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts_observed_target_lambda = []\n",
    "mcts_observed_target_phi = []\n",
    "mcts_observed_target_reward = []\n",
    "for i in 1:length(state.observed_list)\n",
    "    if state.observed_list[i] == 1\n",
    "        push!(mcts_observed_target_lambda, target_lambda[i])\n",
    "        push!(mcts_observed_target_phi, target_phi[i])\n",
    "        push!(mcts_observed_target_reward, target_mean_reward[i])\n",
    "    end\n",
    "end\n",
    "mcts_observed_target_lambda = Float64.(mcts_observed_target_lambda)\n",
    "mcts_observed_target_phi = Float64.(mcts_observed_target_phi)\n",
    "mcts_observed_target_reward = Float64.(mcts_observed_target_reward)\n",
    "\n",
    "\n",
    "angs_list_mcts = []\n",
    "for i in 1:length(action_list_mcts)\n",
    "    # println(i)\n",
    "    action = action_list_mcts[i]\n",
    "    # println(action)\n",
    "    state = state_list_mcts[i]\n",
    "    # println(state)\n",
    "    if action > 1\n",
    "        target = state.target_list[action-1]\n",
    "        push!(angs_list_mcts, get_slew_angle(state.koe, target, state.dt))\n",
    "    else \n",
    "        if i > 1\n",
    "            push!(angs_list_mcts, angs_list_mcts[i-1])\n",
    "        else\n",
    "            push!(angs_list_mcts, (0,0))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "angs_list_mcts = collect(angs_list_mcts)\n",
    "cross_ang_des_mcts = [t[1] for t in angs_list_mcts]\n",
    "along_ang_des_mcts = [t[2] for t in angs_list_mcts];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts_num_observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_list = zeros(length(state_list))\n",
    "# y_list = zeros(length(state_list))\n",
    "x_angle_list = []\n",
    "y_angle_list = []\n",
    "index = 1:length(state_list)\n",
    "for i in 1:length(state_list)\n",
    "    # x_list[i] = state_list[i].x\n",
    "    # y_list[i] = state_list[i].y\n",
    "    push!(x_angle_list, state_list[i].attitude[1])\n",
    "    push!(y_angle_list, state_list[i].attitude[2])\n",
    "end\n",
    "\n",
    "# x_list_mcts = zeros(length(state_list_mcts))\n",
    "# y_list_mcts = zeros(length(state_list_mcts))\n",
    "x_angle_list_mcts = []\n",
    "y_angle_list_mcts = []\n",
    "index_mcts = 1:length(state_list_mcts)\n",
    "for i in 1:length(state_list_mcts)\n",
    "#     x_list_mcts[i] = state_list_mcts[i].x\n",
    "#     y_list_mcts[i] = state_list_mcts[i].y\n",
    "    push!(x_angle_list_mcts, state_list_mcts[i].attitude[1])\n",
    "    push!(y_angle_list_mcts, state_list_mcts[i].attitude[2])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot(index, action_list, label=\"Heuristic\")\n",
    "Plots.plot!(index, action_list_mcts, title=\"Actions with MCTS\", label=\"MCTS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(index, [y_angle_list, y_angle_list_mcts], label=[\"Random\" \"With MCTS\"], title=\"Y angle\")\n",
    "random_along = Plots.plot(index, [y_angle_list, along_ang_des], label=[\"Actual Angle\" \"Desired Angle\"], title=\"Along track angle for Baseline\")\n",
    "mcts_along = Plots.plot(index, [y_angle_list_mcts, along_ang_des_mcts], label=[\"Actual Angle\" \"Desired Angle\"], title=\"Along track angle for MCTS\")\n",
    "Plots.plot(random_along, mcts_along,layout=(1, 2), size=(1000, 400), ylabel=\"Degrees\", xlabel=\"Time (s)\")\n",
    "# save()\n",
    "# plot(index, along_ang_des, label=\"Desired Random\", title=\"Along Track angle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(index, [y_angle_list, y_angle_list_mcts], label=[\"Random\" \"With MCTS\"], title=\"Y angle\")\n",
    "random_along = Plots.plot(index, [x_angle_list, cross_ang_des], label=[\"State Heuristic\" \"Desired Heuristic\"])\n",
    "mcts_along = Plots.plot(index, [x_angle_list_mcts, cross_ang_des_mcts], label=[\"State MCTS\" \"Desired MCTS\"])\n",
    "Plots.plot(random_along, mcts_along,layout=(1, 2), title=\"Cross track angle\", size=(800, 400))\n",
    "# plot(index, along_ang_des, label=\"Desired Random\", title=\"Along Track angle\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globe plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "koe = [state.koe for state in state_list]\n",
    "dts = [state.dt for state in state_list]\n",
    "state_ECEF = zeros(6, length(dts))\n",
    "state_ECI = zeros(6, length(dts))\n",
    "state_lambda = zeros(length(dts))\n",
    "state_phi = zeros(length(dts))\n",
    "for (i, koe) in enumerate(koe)\n",
    "    rv = koe2cart(koe, mu_E)\n",
    "    rv_ecef = ECI_to_ECEF(rv, dts[i])\n",
    "    state_lambda[i] = atand(rv_ecef[2], rv_ecef[1])\n",
    "    state_phi[i] = atand(rv_ecef[3], sqrt(rv_ecef[1]^2 + rv_ecef[2]^2))\n",
    "end\n",
    "\n",
    "layout = @layout [a b]\n",
    "f = Figure(size = (1000, 800), layout=layout)\n",
    "lon,lat,data = GeoDatasets.landseamask(;resolution='c',grid=5)\n",
    "ax1 = Axis(f[1, 1], aspect=DataAspect(), title = \"Heuristic\")\n",
    "sca1 =GLMakie.scatter!(ax1, target_lambda, target_phi, overdraw = true, color = :grey, markersize = 25*target_mean_reward)\n",
    "sca2 =GLMakie.scatter!(ax1, observed_target_lambda , observed_target_phi, overdraw = true, color = :blue, markersize = 25*observed_target_reward)\n",
    "GLMakie.contour!(ax1, lon, lat, data, levels=[0.5], color=:black, linewidth=0.5)\n",
    "path = lines!(ax1, state_lambda, state_phi, overdraw = true, color = :blue, linewidth = 2,)\n",
    "GLMakie.ylims!(ax1, low = -66, high = 66)\n",
    "GLMakie.xlims!(ax1, low = -140, high = -85)\n",
    "# save(f, \"globe.png\")\n",
    "\n",
    "mcts_koe = [state.koe for state in state_list_mcts]\n",
    "mcts_dts = [state.dt for state in state_list_mcts]\n",
    "state_ECEF = zeros(6, length(mcts_dts))\n",
    "state_ECI = zeros(6, length(mcts_dts))\n",
    "mcts_state_lambda = zeros(length(mcts_dts))\n",
    "mcts_state_phi = zeros(length(mcts_dts))\n",
    "for (i, koe) in enumerate(mcts_koe)\n",
    "    rv = koe2cart(koe, mu_E)\n",
    "    rv_ecef = ECI_to_ECEF(rv, mcts_dts[i])\n",
    "    mcts_state_lambda[i] = atand(rv_ecef[2], rv_ecef[1])\n",
    "    mcts_state_phi[i] = atand(rv_ecef[3], sqrt(rv_ecef[1]^2 + rv_ecef[2]^2))\n",
    "end\n",
    "\n",
    "\n",
    "k = 10.580 \n",
    "Δλ = 10\n",
    "p_br = [-110 + k + Δλ, -60]\n",
    "p_bl = [-110 + k - Δλ, -60]\n",
    "p_tr = [-110 - k + Δλ,  60]\n",
    "p_tl = [-110 - k - Δλ,  60]\n",
    "\n",
    "l1 = lines!(ax1, [p_br[1], p_bl[1]], [p_br[2], p_bl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l2 = lines!(ax1, [p_tr[1], p_tl[1]], [p_tr[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l3 = lines!(ax1, [p_br[1], p_tr[1]], [p_br[2], p_tr[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l4 = lines!(ax1, [p_bl[1], p_tl[1]], [p_bl[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "\n",
    "\n",
    "lon,lat,data = GeoDatasets.landseamask(;resolution='c',grid=5)\n",
    "ax2 = Axis(f[1, 2], aspect=DataAspect(), title = \"MCTS with Random Rollouts\")\n",
    "GLMakie.scatter!(ax2, target_lambda, target_phi, overdraw = true, color = :grey, markersize = 25*target_mean_reward)\n",
    "GLMakie.scatter!(ax2, mcts_observed_target_lambda , mcts_observed_target_phi, overdraw = true, color = :blue, markersize = 25*mcts_observed_target_reward)\n",
    "GLMakie.contour!(ax2, lon, lat, data, levels=[0.5], color=:black, linewidth=0.5)\n",
    "lines!(ax2, mcts_state_lambda, mcts_state_phi, overdraw = true, color = :blue, linewidth = 2,)\n",
    "GLMakie.ylims!(ax2, low = -66, high = 66)\n",
    "GLMakie.xlims!(ax2, low = -140, high = -85)\n",
    "# legend_position = Point(5.5, 0.5)  \n",
    "\n",
    "l1 = lines!(ax2, [p_br[1], p_bl[1]], [p_br[2], p_bl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l2 = lines!(ax2, [p_tr[1], p_tl[1]], [p_tr[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l3 = lines!(ax2, [p_br[1], p_tr[1]], [p_br[2], p_tr[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l4 = lines!(ax2, [p_bl[1], p_tl[1]], [p_bl[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "\n",
    "legend = Legend(f[1,3], [sca1, sca2, path, l1], [\"Unobserved targets\", \"Observed targets\", \"Satellite Path\", \"Target Bounding Box\"], framevisible=true)\n",
    "\n",
    "# Adjust these values as needed\n",
    "# legend!(f, ax2, legend, position=legend_position)\n",
    "display(f)\n",
    "# save(f, \"mcts_globe.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_50 = \"../src/obs_site_Earth_50.csv\"\n",
    "dataset_100 = \"../src/obs_site_Earth_100.csv\"\n",
    "dataset_1000 = \"../src/obs_site_Earth2.csv\"\n",
    "\n",
    "\n",
    "df_50 = CSV.read(dataset_50, DataFrame)\n",
    "df_100 = CSV.read(dataset_100, DataFrame)\n",
    "df_1000 = CSV.read(dataset_1000, DataFrame)\n",
    "target_lambda_50 = df_50.lambda\n",
    "target_phi_50 = df_50.phi\n",
    "target_mean_reward_50 = df_50.r_mean\n",
    "target_lambda_100 = df_100.lambda\n",
    "target_phi_100 = df_100.phi\n",
    "target_mean_reward_100 = df_100.r_mean\n",
    "target_lambda_1000 = df_1000.lambda\n",
    "target_phi_1000 = df_1000.phi\n",
    "target_mean_reward_1000 = df_1000.r_mean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GLMakie.Screen(...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fontsize_theme = Theme(fontsize = 25)\n",
    "set_theme!(fontsize_theme)\n",
    "layout = @layout [a b c]\n",
    "f = Figure(size = (1200, 800), layout=layout)\n",
    "lon,lat,data = GeoDatasets.landseamask(;resolution='c',grid=5)\n",
    "ax1 = Axis(f[1, 1], aspect=DataAspect(), title = \"50 Targets\")\n",
    "ax2 = Axis(f[1, 2], aspect=DataAspect(), title = \"100 Targets\")\n",
    "ax3 = Axis(f[1, 3], aspect=DataAspect(), title = \"1000 Targets\")\n",
    "GLMakie.scatter!(ax1, target_lambda_50, target_phi_50, overdraw = true, color = :red, markersize = 20*target_mean_reward_50)\n",
    "GLMakie.contour!(ax1, lon, lat, data, levels=[0.5], color=:black, linewidth=0.5)\n",
    "GLMakie.ylims!(ax1, low = -66, high = 66)\n",
    "GLMakie.xlims!(ax1, low = -140, high = -85)\n",
    "GLMakie.scatter!(ax2, target_lambda_100, target_phi_100, overdraw = true, color = :red, markersize = 20*target_mean_reward_100)\n",
    "GLMakie.contour!(ax2, lon, lat, data, levels=[0.5], color=:black, linewidth=0.5)\n",
    "GLMakie.ylims!(ax2, low = -66, high = 66)\n",
    "GLMakie.xlims!(ax2, low = -140, high = -85)\n",
    "GLMakie.scatter!(ax3, target_lambda_1000, target_phi_1000, overdraw = true, color = :red, markersize = 20*target_mean_reward_1000)\n",
    "GLMakie.contour!(ax3, lon, lat, data, levels=[0.5], color=:black, linewidth=0.5)\n",
    "GLMakie.ylims!(ax3, low = -66, high = 66)\n",
    "GLMakie.xlims!(ax3, low = -140, high = -85)\n",
    "k = 10.580 \n",
    "Δλ = 10\n",
    "p_br = [-110 + k + Δλ, -60]\n",
    "p_bl = [-110 + k - Δλ, -60]\n",
    "p_tr = [-110 - k + Δλ,  60]\n",
    "p_tl = [-110 - k - Δλ,  60]\n",
    "l1 = lines!(ax1, [p_br[1], p_bl[1]], [p_br[2], p_bl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l2 = lines!(ax1, [p_tr[1], p_tl[1]], [p_tr[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l3 = lines!(ax1, [p_br[1], p_tr[1]], [p_br[2], p_tr[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l4 = lines!(ax1, [p_bl[1], p_tl[1]], [p_bl[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l5 = lines!(ax2, [p_br[1], p_bl[1]], [p_br[2], p_bl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l6 = lines!(ax2, [p_tr[1], p_tl[1]], [p_tr[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l7 = lines!(ax2, [p_br[1], p_tr[1]], [p_br[2], p_tr[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l8 = lines!(ax2, [p_bl[1], p_tl[1]], [p_bl[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l9 = lines!(ax3, [p_br[1], p_bl[1]], [p_br[2], p_bl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l10 = lines!(ax3, [p_tr[1], p_tl[1]], [p_tr[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l11 = lines!(ax3, [p_br[1], p_tr[1]], [p_br[2], p_tr[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "l12 = lines!(ax3, [p_bl[1], p_tl[1]], [p_bl[2], p_tl[2]], overdraw=true, color=:orange, linestyle=:solid, linewidth=2,)\n",
    "\n",
    "\n",
    "display(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD PLots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = plot(x_list, y_list, label=\"Position\", aspect_ratio=:equal, legend=:bottomleft, dpi=500)\n",
    "\n",
    "# for i in 1:length(x_list)\n",
    "#     if action_list[i] != 1\n",
    "#         plot!([x_list[i], target_x_r[action_list[i] - 1]], [y_list[i], target_y_r[action_list[i] - 1]], label=\"\", c=\"gray\")\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# reward_round = round(reward_total, digits=2)\n",
    "# text_to_display = \"Reward: $reward_round\"\n",
    "# annotate!((-35, 30, text(text_to_display, 10, :left, :center, :black)))\n",
    "\n",
    "\n",
    "# scatter!(target_x_r,target_y_r, mc=\"green\", label=\"Unobserved targets\", markersize = 10*target_reward_r)\n",
    "# scatter!(observed_target_x_r,observed_target_y_r, mc=\"blue\", label=\"Observed targets\", markersize = 10*observed_target_reward_r)\n",
    "# display(plt)\n",
    "\n",
    "# savefig(plt, \"random_targeting.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = plot(x_list_mcts, y_list_mcts, label=\"Position\", aspect_ratio=:equal, legend=:bottomleft, dpi=500)\n",
    "\n",
    "# for i in 1:length(x_list_mcts)\n",
    "#     if action_list_mcts[i] != 1\n",
    "#         plot!([x_list_mcts[i], target_x[action_list_mcts[i] - 1]], [y_list_mcts[i], target_y[action_list_mcts[i] - 1]], label=\"\", c=\"gray\")\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# reward_mcts_round = round(reward_total_mcts, digits=2)\n",
    "# text_to_display = \"Reward: $reward_mcts_round\"\n",
    "# annotate!((-35, 30, text(text_to_display, 10, :left, :center, :black)))\n",
    "\n",
    "# scatter!(target_x,target_y, mc=\"green\", label=\"Unobserved targets\", markersize = 10*target_reward)\n",
    "# scatter!(observed_target_x,observed_target_y, mc=\"blue\", label=\"Observed targets\", markersize = 10*observed_target_reward)\n",
    "\n",
    "# display(plt)\n",
    "# savefig(plt, \"mcts_targeting.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
